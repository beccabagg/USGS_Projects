# This script analyzes total station data to extract the summary metadata data frames
# This script requires a CSV to be uploaded by inserting the local path to the file on your system
# It is recommended to set the working directory at the top of the script to your local desktop

# ----------------------------------------------------------------------------
# NOTE: This script requires 2 elevation values for each location. 
# Additional values should be removed from the CSV prior to importing
# Code by Rebecca Baggott, contact rbaggott@usgs.gov for questions
# ----------------------------------------------------------------------------

# Load necessary libraries
# List of packages to install
packages <- c("dplyr", "tidyr", "xml2", "shiny")

# Loop through packages and install if not already installed
for (package in packages) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package)
    library(package, character.only = TRUE)
  }
}

# Define UI for the application
ui <- fluidPage(
  # Application title
  titlePanel("Automated Total Station Data Analyzer"),
  
  # README Section
  p("Welcome to the Automated Total Station Data Analyzer web application! This tool is designed to analyze CSV data generated by total stations, specifically model Trimble S7 with a TSC5. To begin, please upload a total station CSV file by entering the local path to the file on your system."),
  
  p(tags$strong("Important Requirements:")),
  p("For this script to function correctly, please ensure the following:"),
  tags$ul(
    tags$li("Each point name in the dataset must have exactly two elevation values. Any additional elevation values should be removed from the CSV file before importing."),
    tags$li("All replicate point names must be identical in spelling and case throughout the entire dataset to ensure accurate analysis. For example, 'RM4' and 'rm4' will be treated as different point names. It is recommended to edit the total station CSV output file to correct any spelling or case errors before import.")
  ),
  
  p(tags$strong("Entering Hex-bolt and Dial Readings:")),
  p("You can enrich the summary data by entering Hex-bolt and Dial readings. Simply input the corresponding values and click the 'Update Summary' button to include them in the analysis. Similarly, you can enter metadata regarding the party name, site name, site number, and date, and then select 'Update Info' to save these details. Should any data be entered incorrectly, select Analyze Data to refresh the page and remove entered values."),
  
  p(tags$strong("Quality Assurance/Quality Control (QA/QC):")),
  p("The QA/QC section of this script computes the average error of the Vertical Angle (VA) for each point. This process involves several steps:"),
  tags$ul(
    tags$li("The difference between each paired observation of the vertical angle (in degrees) is calculated."),
    tags$li("This difference is then normalized by the average slope distance corresponding to those observations to calculate the error."),
    tags$li("Finally, the error values for all observations of each point are averaged to provide a singular error metric per point.Error values are expressed as a percentage. Values greater than 0.1 will be highlighted."),
  ),
  
  p("By analyzing these error values, users can evaluate the accuracy and reliability of total station data collection."),
  
  p(tags$em("This application was developed by Rebecca Baggott. If you have any questions or require assistance, please contact rbaggott@usgs.gov.")),
  p(tags$em("Export to XML options coming soon!")),
  
  sidebarLayout(
    sidebarPanel(
      fileInput("file1", "Upload CSV File", 
                accept = c("text/csv", "text/comma-separated-values,text/plain", ".csv")),
      actionButton("analyze", "Analyze Data"),
      hr(),
      
      textInput("point_name", "Enter Point Name"),
      textInput("hex_input", "Enter Dial/Hex Reading"),
      actionButton("update_summary", "Update Summary"),
      hr(),
      
      textInput("party_name", "Enter Party Name"),
      textInput("site_name", "Enter Site Name"),
      textInput("site_number", "Enter Site Number"),
      textInput("date", "Enter Date"),
      actionButton("update_info", "Update Info"),
    ),
    mainPanel(
      tableOutput("data_summary"),
      tableOutput("info_data"),
      tableOutput("info"),
      tableOutput("average_percent_error")  
    )
  )
)

# Define server logic
server <- function(input, output) {
  data_summary <- reactiveVal(data.frame())
  average_percent_error <- reactiveVal(data.frame())  # Reactive value for average percent error
  
  observeEvent(input$analyze, {
    req(input$file1)
    
    # Load the CSV file
    dat <- read.csv(input$file1$datapath, header = FALSE)
    
    # Identify rows with blank entries
    blank_rows <- which(apply(dat, 1, function(x) all(is.na(x) | x == "")))
    
    # Split the data into several DataFrames
    data_frames <- list()
    start_idx <- 1
    for (i in seq_along(blank_rows)) {
      end_idx <- blank_rows[i] - 1
      if (end_idx >= start_idx) {
        data_frames[[i]] <- dat[start_idx:end_idx, ]
      }
      start_idx <- blank_rows[i] + 1
    }
    
    # Check for any remaining data after the last blank row
    if (start_idx <= nrow(dat)) {
      data_frames[[length(data_frames) + 1]] <- dat[start_idx:nrow(dat), ]
    }
    
    # Remove completely blank columns from DataFrames
    remove_blank_columns <- function(df) {
      df %>% select(where(~ !all(is.na(.) | . == "")))
    }
    
    # Clean each DataFrame
    for (i in seq_along(data_frames)) {
      df <- data_frames[[i]]
      cleaned_df <- remove_blank_columns(df)
      data_frames[[i]] <- cleaned_df
    }
    
    # Process dat1
    dat1 <- data_frames[[1]]
    dat1 <- dat1 %>% separate(V1, into = c("Metadata Variable Name", "Value"), sep = ":", fill = "right")
    
    dataframe_names <- seq_along(data_frames)
    # Set first row as column names for each DataFrame
    for (i in dataframe_names) {
      df <- data_frames[[i]]
      colnames(df) <- as.character(unlist(df[1, ]))
      data_frames[[i]] <- df[-1, ]
    }
    
    # Select the QA/QC Columns
    # Define the target column names for dat6
    target_columns_dat6 <- c("Point name", "Round", "Observation", "Face", "VA", 
                             "Slope distance", "Target height", "HA (raw)", 
                             "VA (raw)", "Std Dev (cc)", "Slope distance (raw)", 
                             "Prism constant", "Temperature", "Pressure", 
                             "Parts per million", "Refraction const.", 
                             "Refraction correction", "Curvature correction", "Used")
    
    # Define the target column names for dat7, which includes an additional column
    target_columns_dat7 <- c("Point name", "Round", "Observation", "Face", "VA", 
                             "Slope distance", "Target height", "HA (raw)", 
                             "VA (raw)", "Std Dev (cc)", "Slope distance (raw)", 
                             "Prism constant", "Temperature", "Pressure", 
                             "Parts per million", "Refraction const.", 
                             "Refraction correction", "Curvature correction", 
                             "Reference point", "Used")
    
    # Initialize dat6 and dat7
    dat6 <- NULL
    dat7 <- NULL
    
    # Search for the DataFrame with the target columns for dat6
    for (df in data_frames) {
      # Check if the DataFrame has all target columns for dat6
      if (all(target_columns_dat6 %in% colnames(df))) {
        dat6 <- df
        break  # Exit loop if found
      }
    }
    
    # Check if a suitable DataFrame for dat6 was found
    if (is.null(dat6)) {
      stop("No DataFrame with the specified columns for dat6 found.")
    }
    
    # Search for the DataFrame with the target columns for dat7
    for (df in data_frames) {
      # Check if the DataFrame has all target columns for dat7
      if (all(target_columns_dat7 %in% colnames(df))) {
        dat7 <- df
        break  # Exit loop if found
      }
    }
    
    # Check if a suitable DataFrame for dat7 was found
    if (is.null(dat7)) {
      stop("No DataFrame with the specified columns for dat7 found.")
    }
    
    # Remove extra columns
    dat7 <- dat7[, -19]
    
    QA <- rbind(dat6, dat7)
    QA <- QA[ ,c(1, 4, 5, 6)]
    colnames(QA) <- c("Point_name", "Face", "VA", "Slope_distance")
    
    # Ensure the VA and Slope_distance columns are numeric
    QA$VA <- as.numeric(as.character(QA$VA))
    # Convert gradiens to degrees
    QA$VA <- QA$VA *(0.9)
    QA$Slope_distance <- as.numeric(as.character(QA$Slope_distance))
    
    # Remove any rows with NA values
    QA <- QA %>%
      filter(!is.na(VA) & !is.na(Slope_distance))
    
    # Assuming QA is your dataframe
    QA_result <- QA %>%
      group_by(Point_name) %>%
      mutate(
        # Create a row number for each observation within the group
        row_id = row_number(),
        # Calculate the differences for VA and Slope_distance
        VA_diff = abs(VA - lag(VA)),
        Slope_distance_diff = (Slope_distance - lag(Slope_distance)/2)
      ) %>%
      # Filter to keep only every second row (the result of Row 1 - Row 2, Row 3 - Row 4, etc.)
      filter(row_id %% 2 == 0) %>%
      select(Point_name, VA_diff, Slope_distance_diff)
    
    # Calculate Percent Error
    QA_result <- QA_result %>%
      mutate(
        Percent_Error_VA = ((VA_diff / Slope_distance_diff)*100)
      ) %>%
      # Replace Inf values with NA
      mutate(
        Percent_Error_VA = ifelse(is.infinite(Percent_Error_VA), NA, Percent_Error_VA)
      )
    
    # After calculating the average percent error
    avg_percent_error <- QA_result %>%
      group_by(Point_name) %>%
      summarize(
        Average_Percent_Error_VA = round(mean(Percent_Error_VA, na.rm = TRUE), 3),
        .groups = 'drop'
      ) %>%
      rename(
        `Point Name` = Point_name,
        `Average Error` = Average_Percent_Error_VA
      )
    
    # Sort the average percent error by Average Error from largest to smallest
    avg_percent_error <- avg_percent_error %>%
      arrange(desc(`Average Error`))
    
    # Update the reactive variable
    average_percent_error(avg_percent_error)  # Update the reactive variable
    
    
    # Identify DataFrame with target column names
    target_column_names <- c("Point name", "Target height", "HA", "VA", "Slope distance", "Elevation", "Adjust", "Adj Z", "Reference point")
    df_to_keep <- NULL
    
    for (i in dataframe_names) {
      df <- data_frames[[i]]
      if (all(target_column_names %in% colnames(df))) {
        df_to_keep <- i
        break
      }
    }
    
    # Rename DataFrames
    info <- dat1
    data <- data_frames[[df_to_keep]]
    
    # Process 'data'
    if (exists("data")) {
      data$`Adj Z` <- as.numeric(as.character(data$`Adj Z`))
      problematic_entries <- data %>%
        filter(is.na(`Adj Z`)) %>%
        select(`Point name`, `Adj Z`)
      
      data <- data %>% filter(!is.na(`Adj Z`))
      
      if (nrow(data) > 0) {
        data_summary_value <- data %>%
          group_by(`Point name`) %>%
          summarize(`Adj Z` = mean(`Adj Z`, na.rm = TRUE), .groups = 'drop')
        
        # Initialize columns to NA
        data_summary_value <- data_summary_value %>%
          mutate(
            `Adj Z` = formatC(`Adj Z`, format = "f", digits = 3),  # Convert to numeric; NA will remain NA
            `Dial/Hex Reading` = NA,  # Initialize Dial/Hex Reading to NA
            `Difference` = NA  # Initialize the Difference column
          )
        
        
        # Calculate Difference — ensure both values are numeric or NA
        data_summary_value <- data_summary_value %>%
          mutate(
            `Dial/Hex Reading` = as.numeric(`Dial/Hex Reading`),  # Ensure Dial/Hex Reading is numeric
            Difference = ifelse(is.na(`Adj Z`) | is.na(`Dial/Hex Reading`), NA, 
                                `Adj Z` - `Dial/Hex Reading`)  # Calculate difference only if both are numeric
          )
        

        data_summary(data_summary_value)  # Update the reactive data_summary
      } else {
        data_summary(data.frame("No valid data available after filtering."))
      }
    } else {
      data_summary(data.frame("Data frame 'data' does not exist."))
    }
    
    # Render tables in the UI
    output$data_summary <- renderTable(data_summary())
    output$info <- renderTable(info)
    
    # New rendering for the average percent error with highlighting
    output$average_percent_error <- renderUI({
      req(average_percent_error())  # Ensure the reactive data is available
      df <- average_percent_error()  # Get the current data
      
      # Create an HTML table
      table_html <- "<table class='table'>"
      
      # Table Header
      table_html <- paste0(table_html, "<thead><tr><th>Point Name</th><th>Average Error</th></tr></thead>")
      table_html <- paste0(table_html, "<tbody>")
      
      # Fill in table rows
      for (i in 1:nrow(df)) {
        point_name <- df[i, "Point Name"]
        average_error <- df[i, "Average Error"]
        
        # Check the value and apply conditional formatting
        if (average_error > 0.1) {
          table_html <- paste0(table_html, "<tr><td>", point_name, "</td><td style='background-color: yellow;'>", average_error, "</td></tr>")
        } else {
          table_html <- paste0(table_html, "<tr><td>", point_name, "</td><td>", average_error, "</td></tr>")
        }
      }
      
      table_html <- paste0(table_html, "</tbody></table>")
      
      # Return the HTML content
      HTML(table_html)
    })
  })
  
  observeEvent(input$update_info, {
    req(input$party_name, input$site_name, input$site_number, input$date)
    
    # Create a new data frame for the info section
    info_data <- data.frame(
      Variable = c("Party Name", "Site Name", "Site Number", "Date"),
      Value = c(input$party_name, input$site_name, input$site_number, input$date),
      stringsAsFactors = FALSE
    )
    
    # Set the first column as row names
    rownames(info_data) <- info_data$Variable
    
    # Render the new info table
    output$info_data <- renderTable(info_data)
  })
  
  observeEvent(input$update_summary, {
    req(input$point_name, input$hex_input)
    
    point_name <- input$point_name
    hex_value <- as.numeric(input$hex_input)
    
    current_summary <- data_summary()
    
    if (nrow(current_summary) > 0) {
      # Check if the entered Point Name exists in the summary
      if (point_name %in% current_summary$`Point name`) {
        # Update the Hex/Dial Reading for the specified Point Name
        current_summary$`Dial/Hex Reading`[current_summary$`Point name` == point_name] <- hex_value
      } else {
        # Optional: Add a new row if the Point Name does not exist
        new_row <- data.frame(`Point name` = point_name, `Adj Z` = NA, `Dial/Hex Reading` = hex_value, `Difference` = NA, check.names = FALSE)
        current_summary <- rbind(current_summary, new_row)
      }
      
      # Calculate the Difference
      current_summary <- current_summary %>%
        mutate(Difference = as.numeric(`Adj Z`) - `Dial/Hex Reading`)
      
      data_summary(current_summary)
    }
  })
}

# Run the application 
shinyApp(ui = ui, server = server)